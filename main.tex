\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
%\usepackage{natbib}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}

\begin{document}

\title{%Toward Intersubjectivity in Developmental Agents: Integrating Probabilistic Affordances in the Emergent Model of the Environment.
%integrating probabilist anticipations of displacement of other agents in the emergent model of the environment
%Learning to anticipate displacements of other agents
%Probabilistic interactive learning of moving/mobile agents to foster intersubjectivity with other agents
Discovering, recognizing, and localizing dynamic affordances to adapt to unknown agents
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Simon L. Gay}
\IEEEauthorblockA{\textit{LCIS, University of Grenoble Alpes} \\
Valence, France \\
simon.gay@lcis.grenoble-inp.fr}
\and
\IEEEauthorblockN{Jean-Paul Jamont}
\IEEEauthorblockA{\textit{LCIS, University of Grenoble Alpes} \\
Valence, France \\
Jean-Paul.Jamont@lcis.grenoble-inp.fr}
\and
\IEEEauthorblockN{Olivier L. Georgeon}
\IEEEauthorblockA{\textit{EA1598, Lyon Catholic University} \\
\textit{LIRIS, Claude Bernard University} \\
Lyon, France \\
ogeorgeon@univ-catholyon.fr}
}

\maketitle

\begin{abstract}
We present an architecture for self-motivated and environmentally-agnostic agents to integrate non-predictible elements in their emerging model of their environment. This approach aims designing agents that construct their own model of their environment through experience, rather than exploiting pre-coded knowledge. Over time, the agent learns the relation between its perception of objects and the interactions that they afford, in the form of data structures, called signatures of interaction. These signatures are used to recognize and localize objects (or affordances) in surrounding environment, that are stored and tracked in a spatial memory, and used to generate behaviors satisfying agent's motivational principles. A long term objective of this approach is to study the interaction between multiple agents and the emergence of collaborative or competitive behaviors. Emergence of such behaviors requires the possibility to integrate other agents in the environment model and predict possible actions of these agents. In this paper, we propose a novel architecture of signature of interaction that can define, recognize and localize non-predictible affordances as a first step toward agent intersubjectivity.
\end{abstract}

\begin{IEEEkeywords}
developmental learning, interactionism, affordance, autonomous mental development, spatial awareness.
\end{IEEEkeywords}

\section{Introduction}

We address the problem of how an artificial agent that learns an emergent model of its environment through interaction can acquire knowledge about mobile entities that move freely in the environment (e.g., other agents). 
We build upon our previous work that learned a model of fixed entities and their geometrical properties. The addition into the environment of entities that move according to their own rules makes the learning even more challenging.

%long term goal of the emergence of collaborative behaviors between artificial agent that initially ignores elements that compose its environment and geometrical properties of its environment. Such an agent can be defined as environment-agnostic [].
%\newline
%APPLICATIONS MULTI-AGENT ?
%\newline
%Generating collaborative behaviors require the ability to anticipate other agents' intentions. This intersubjectivity first requires to be able to define and recognize other agents as parts of the environment.

%In this paper, we focus on the problem of recognizing and localizing non-predictible affordances.



%- introduction br√®ve du DL, introduction du vocabulaire\newline

This study is situated within the paradigm of artificial constructivist learning \cite{wang_new_2012} and enactive learning \cite{froese2009enactiveAI}. 
In this paradigm, the learning occurs through the enaction of control loops that implement Piagetian \textit{sensorimotor schemes} \cite{piaget2013construction}.  
We initialize the agent with a predefined set of control loops called \textit{primitive interactions}. 
We associate each primitive interaction with a predefined numerical \textit{valence}.
We design the agent's software so that the agent seeks to enact interactions that have positive valences, and to avoid enacting interactions that have negative valences. 
Such software endows the agent with a kind of self motivation that we have called \textit{interactional motivation} \cite{georgeon_interactional_2012}.
This view on self motivation relates to the notion of \textit{intrinsic motivation} of artificial agents for \textit{developmental learning} \cite[e.g.]{oudeyer_intrinsic_2007}.
For a complete description, we refer the reader to our previous papers in which we have called this approach \textit{Radical Interactionism} (RI) \cite{georgeon:radical} and \textit{artificial interactionism} \cite{GuillerminGeorgeon2022}. 
Overall, the learning is \textit{unsupervised}. 
There are no human-defined labels attached with perceptions or with categories of entities, no pre-coded ontology of the world, no semantics associated with action data or sensory data.  

%The agent perceives and interprets its environment by identifying affordances [] rather than recognizing objects on the basis of predefined features. This approach addresses the knowledge grounding problem [] by letting knowledge of objects arise from experience.

In designing agents that autonomously learn to interact with other agents, we pursue the long-term goal of allowing the emergence of collective behaviors within groups of artificial agents. Generating collective behaviors involving other agents requires overcoming two main problems:

1) learning to define, recognize and localize other agents that make individual movements in the environment,

2) inferring the intentions of these other agents based on their own environmental contexts, which is related to the intersubjectvity problem.

This paper focuses on the resolution of the first problem. 
It is subdivided as follow: Section II summarizes and formalizes the Radical Interactionism model and the architecture constructing the environment model. Section III presents a model for defining and recognizing probabilistic affordances, and Section IV presents a mechanism to recognize and localize distant probabilistic affordances in space. Finally, Section V encompasses some conclusive remarks and future development of the intersubjectivity problem.

\section{The Radical Interactionism (RI) model}

%Developmental learning [17] makes the assumption that the agent is agnostic of its environment [5]. This assumption prohibits considering that the agent can identify states, both for its environment and for itself. 

In contrast with most machine learning approaches, an RI agent cannot directly detect the state of its environment through perceptual data. 
The agent's input data is not a percept of the state of the environment but an outcome of a control loop. 
An RI agent learns and exploits regularities in sequences of the control loops offered by its coupling with its environment.  
The learning mechanism differs from reinforcement learning (e.g., as it is typically implemented in a Partially Observable Markov Decision Process, POMDP) by the fact that RI agents have no reward defined as a function of the system's state. 
Our goal is not to design agents that reach predefined goal states or maximize a reward value, but to generate open-ended learning and collective behaviors.
%This theoretically simplifies the system complexity as it depend on the complexity of agent's sensorimotor system rather than environment complexity.

Let $I$ be the set of predefined primitive interactions (pointers to predefined control loops), and $\nu_i \in \mathbb{R}$ the predefined valence of primitive interaction $i \in I$.
At the beginning of step $t$, the agent selects an \textit{intended interaction} $i_t \in I$. 
An example consists in moving forward for a predefined amount of time while detecting no obstacle.
At the end of step $t$, the agent is informed of the \textit{enacted interaction} $e_t \in I$ that was actually enacted. 
If $i_t = e_t$ then the enaction is a success. The agent did move forward without detecting an obstacle. 
Otherwise, the tentative enaction of $i_t$ was a failure. 
For example, the agent actually enacted another interaction consisting in bumping into an obstacle, which may have a negative valence.
An RI agent learns to anticipate the results of its interactions, and tries to enact interactions that have a high valences.

In some studies \cite{}, we have extended the RI model to help discovering spatial regularities of the environment, by allowing the simultaneous enaction of multiple interactions. 
The Parallel RI (PRI) considers additional stimuli that cannot be separated from the movement that produced them. 
The optical flow is an example of such stimuli, that must be associated to a movement to characterize a unique position in space. 
Thus, the PRI model considers \textit{primary} interactions as sensorimotor schemes (action,perception), and \textit{secondary} interactions as a couple (interaction, stimulus). 
Formally, a PRI algorithm starts with a set I of interactions (primary and secondary). 
At step t, the agent selects an intended interaction $i_t$, and is informed, at the end of step t of a set of interactions $E_t=\{e_k\}t$ that were enacted, consisting of a primary interaction and a set of secondary interactions associated to this primary interaction.

Previous PRI architectures demonstrated the possibility, for an environmentally-agnostic agent, to define and recognize elements affording their interactions, to localize distant affordances, and to store and keep trace of them in an emergent structure, called space memory, allowing to generate an implicit context that is used to generate behaviors satisfying motivational principles. 

A subsequent model also showed the possibility to integrate elements that move with a uniform movement, by considering sequences of at least two consecutive interactions \cite{gay:dynamic}. However, these models fail to integrate elements whose movement cannot be predicted, as it is not possible to associate the presence of an observed element to a specific affordance.

%Next Sections III and IV present adaptation of mechanisms to define and recognize affordances, ant to localize distant affordances, in a form that is compatible with specifications of the space memory model.


\section{Integrating Probabilistic Affordances}

%The signature mechanism proposed in this section propose to cope with the probabilistic affordance problem by separating the certitude of presence of the signature and the probability of success of the associated interaction.

This section describe and formalize the machanisms for defining and recognizing affordances of interactions, called signature mechanism, and its adaptations for probabilistic affordances.

The signature mechanism is based on the assumption that the result of enacting an interaction depends on a limited context of elements in the environment. Such contexts thus relates to the concept of affordances proposed by Gibson \cite{gibson:affordances}, and especially the formalization given by Chemero \cite{chemero:affordance} and Stoffregen \cite{stoffregen:affordance}, who consider an affordance as a property emerging from the agent-environment coupling. As a PRI agent can only perceive its environment through enacted interactions, we define the signature $S_i$ of an interaction $i$ as structure, learned through experience, characterizing one (or more) ensemble(s) of interactions $\{j_k\}$ whose enaction (i.e. $\{j_k\} \subset E_t$) can characterize the presence of the element affording $i$, and thus, the enactability of $i$.  This approach addresses the knowledge grounding problem \cite{harnad:grounding} by letting knowledge of objects arise from experience.

Formally, a signature is a function $S_i : \mathcal{P}(I) \rightarrow [-1;1]$, where $\mathcal{P}(I)$ is the partition of possible contexts, that gives a numerical value in $[-1, 1]$ that reflects the possibility of successfully enacting $i$ in an interactional context $E$ (1 for an absolute certainty of success and -1 for an absolute certainty of failure). $S_i$ is learned and reinforced when $i$ succeeds or fails to generate accurate predictions. %Previous implementations of signatures used formal neurons [ ] or discrete ensembles of interactions [ ].

A signature must be \textit{reversible}: it must be possible to define a function $\hat{S}_i : \{1;-1\} \rightarrow \mathcal{P}(\mathcal{P}(I))$ that can provide \textit{minimum contexts} (i.e. $\nexists E_1,\!E_2\!\in\!\hat{S}_i(x), x\!\in\!\{1;-1\} / E1\!\subset\!E2$) affording $i$ ($\hat{S}_i(1)$) and preventing enaction of $i$ ($\hat{S}_i(-1)$). We note $C_k^{S_i} \in S_i$ such a minimal context affording $i$.

However, previous implementations fails to integrate probabilistic affordances, as the presence of the affordance may still lead to a failure of the interaction. We thus propose to first separate certainty of presence of affordance and probability of success, and then to differentiate multiple contexts that may lead to a success of the interaction.

%Before you begin to format your paper, first write and save the content as a
%separate text file. Complete all content and organizational editing before
%formatting. Please note sections \ref{AA}--\ref{SCM} below for more information on
%proofreading, spelling and grammar.

%Keep your text and graphic files separate until after the text has been
%formatted and styled. Do not number text heads---{\LaTeX} will do that
%for you.

\subsection{Separating certainty and probability}\label{AA}

When the agent tests an interaction, three cases can be defined from an external observer's perspective:
\begin{enumerate}
\item The affordance is present at the right place, and the agent can enact the interaction successfully. (e.g. a prey is in front of the agent, and the agent could grabs the prey).
\item The affordance is present, but the interaction fails. (e.g. a prey is i front of the agent, but the prey moved and the agent missed catching the prey).
\item The affordance is absent, leading to a failure of the interaction. (e.g. there is no prey in front of the agent, leading to a certain failure of catching a prey).
\end{enumerate}
From the agent's perspective, the results of situations 2 and~3 cannot be distinguished, as they have the same result. Moreover, situations 2 prevents the construction of the signature, and thus the possibility to distinguish situations 1 and 2 from situations 3.
However, our preliminary tests showed an interesting results: despite remaining negative due to situations 2, the signature responses are slightly higher in case of situations 1-2 than in situations 3. Indeed, the existence of situations 1 influence the signature, allowing the context of interactions corresponding to the affordance to emerge while remaining insufficient to predict a success.

From this observation, we propose to use the average prediction in case of failure ($\overline{S_i^f}$) as a threshold to distinguish situations 2 and 3 after a failure. Then, when the interaction failed in an assumed situation 2 (i.e. $S_i(E_t)>\overline{S_i^f}$), the signature is not reinforced, which limit the influence of situations 2 in preventing the emergence of the signature. This principle is applied when $\overline{S_i^f}$ is lower than a threshold, assuming that the signature started to emerge (we used a threshold of -0.9).

%The average value of negative predictions is evaluated using:
%\begin{equation}
%\overline{S_i^f}^{t+1}~=~{{\overline{S_i^f}^{t} \times n ~+~ S_i(E_t)} \over{n+1}}~, when~ S_i(E_t)<0
%\end{equation}
%Then, when the prediction $S(E_t)>\overline{S^-}$, the signature is not learned in case of failure. This principle thus decrease the influences of situations that are expected to be situation 2. %, allowing the construction of the signature. 
%This principle is applied when the average prediction $\overline{S^-}$ is lower than a treshold (we used a value of -0.9), to let the context of interaction corresponding to the affordance starting to emerge in the signature.

Several interactions can be prevented by the presence of an element (e.g. moving a step forward is expected to success, until an obstacle appears). In such cases, situations 1' are related to the failure of the interaction, and situations 2' and 3' to its success. As situations 2' and 3' are expected to be more frequent than situations 1', the average of predictions will converge to a positive value. We thus used the average of positive predictions $\overline{S_i^s}$ as a threshold to prevent the signature reinforcement in case of success in an assumed situation 2' (i.e. $S_i(E_t)<\overline{S_i^s}$). This principle is applied when $\overline{S_i^s}$ is greater than a threshold (we used a threshold of 0.9).


%and thus are expected to success when the affordance is absent, we also define the average value of positive predictions $\overline{S^s}$. When this average value is greater than a treshold (we used a value of 0.9), a prediction lower than $\overline{S^+}$ is not learned in case of success.

It is also possible to define the ratio of interaction success when the prediction $S(E_t)$ is greater than the average $\overline{S^f}$ (or interaction failure when $S(E_t)$ is lower than the average $\overline{S^s}$), implying that the agent is in a situation of type 1 or 2 (or 1' or 2'). This ratio thus measures the probability that the presence of the affordance actually affords successfully the interaction.



%-impl√©mentation\newline

%This signature mechanism was tested on an artificial agent moving in a 2-dimensional discrete environment. The sensorimotor possibilities of the agent define a list of five primary interactions, listed below:

%- \includegraphics[width=0.015\textwidth]{img/mf0.pdf} move forward by one step

%- \includegraphics[width=0.015\textwidth]{img/mf1.pdf} bump in a solid element 

%- \includegraphics[width=0.015\textwidth]{img/mf2.pdf} eat something edible 

%- \includegraphics[width=0.02\textwidth]{img/rt0.pdf} turn right by $90^\circ$ 

%- \includegraphics[width=0.02\textwidth]{img/lt0.pdf} turn left by $90^\circ$ 

%Interactions move forward, bump and eat are considered as mutually alternative: intending one of these interactions may lead to the enaction of one of the two others. %(and thus the failure of this interaction).

%We add a set of secondary interactions provided by the agent‚Äôs visual system, that can detect colors among {red,green, blue}, and measure distances.  Secondary (visual) interactions consist in seeing a red, green or blue element while enacting a primary interaction, at a certain (but initially unknown) position of space. The interaction bump, that does not produce movement, does not generate visual interactions. We discretize the visual field as a regular grid of 15 √ó 8 positions centered on the agents that matches the grid of the environment. We thus define 4 √ó 3 √ó 15 √ó 8 = 1440 possible secondary interactions.

%Signatures of interactions are implemented in a similar way than in []. Each signature is composed of a unique formal neuron. DESCRIPTION

%As we only study the emergence of signatures, we define a unique learning mechanism that foster interactions with low certitude of success or failure. Note that a secondary interaction can be candidate if its associated primary interaction is predicted as a success with a high certitude.

%The environment is populated by three types of objects offering spatial regularities that the agent can discover by interacting with them, and characterized by a color that makes them recognizable through visual interactions:

%- wall (green), affording bump

%- algae (red), that are walkthroughable (and thus useless in the agent's perspective).

%- fishes (blue), affording eat.

%The fishes move randomly in the environment: at each simulation step, a fish can move in one of these five directions, with a probability of 20\%: immobile, left, right, top, bottom. If the fish cannot move in the selected direction because of an obstacle (wall, alga or other fish), the fish remains at its current position, making the immobile situation probability slightly higher than other directions.

%All object are opaques: the agent cannot perceive an element behind another one.



%-r√©sultats et analyse des diagrammes\newline
%We then let the agent behaves in its environment, driven by the signature learning mechanism.
%The signature of interaction bump, that is fully predictable, emerges after nearly 5000 simulation step, and is similar to the signature obtained in previous models []: the agent successfully associated this interaction to the interactions related to the presence of a green object in front of the agent. Signatures of turn interactions, that cannot fail, are strongly related to the neuron bias of the signatures.

%Signatures of interactions move forward and eat take more time to emerge, as their are related to a larger diversity of contexts and the affordances are probabilistic (fishes). After 35~000 simulation steps, the signature of eat associates the success of eat to the presence of a blue object in different positions around the agent. The signature of interaction move forward is associated to the absence of a blue element around the agent, but also the absence of a green element in front of the agent.

%After 50 000 simulation steps, most of signatures of secondary interactions related to static elements (red and green) emerged and stabilized. Most of signatures related to seeing blue elements are stabilized after 100 000 simulation steps. Interactions related to seeing a green or red element designate elements of the same color but on a different position in space. From an external point of view, the spatial offset between the visual secondary interaction and the element designated by its signature matches the movement performed by the enation of its associated primary interaction. This property is used for signature projection and distant affordance detection [ ] (details in Section IV).

%\begin{figure}[htbp]
%\centerline{\includegraphics[scale=0.6]{img/Signatures1.pdf}}
%\caption{Signatures of (from left to right) move forward, bump and eat, obtained after 35 000 simulation steps. A signature is characterized by a set of weights of a formal neuron, connected to a binary vector indicating enacted interactions. As external observers, we can organize these weights to make signatures more readable. First, weights of secondary interaction are grouped according to their associated primary interaction (from top to bottom: forward, eat, turn left, turn right). Weights associated to primary interactions and the bias are represented with squares below. Then each group is organized to match the associated position in space, relative to the agent (orange triangle). Then colors are overlapped to generate signatures under the form of a RGB image. Interaction bump (middle) is afforded by a green object in front of the agent, but also after bumping. Eat is afforded by the presence of a blue element that is located around the agent. Forward is prevented by the absence of a green object in front of the agent or by a blue object around the agent (dark red and yellow blobs), and cannot be enacted after bump. Weights related to interactions associated to eat are low, due to the rarity of this primary interaction.}
%\label{fig}
%\end{figure}


%\begin{figure}[htbp]
%\centerline{\includegraphics[scale=0.6]{img/Signatures2.pdf}}
%\caption{Sample of signatures of secondary interactions recorded after 100 000 simulation step. %From left to right: seeing a red element while moving forward, seeing a blue element while turning left, and seeing a red element while turning right, at the position shown by the red square. The offset between the position associated to the interaction and the position of its affordance correspond to the movement produced by the primary interaction. This property is exploited to project signatures and detect distant affordances. The signatures of seeing a blue element show the same pattern than eat, and have a ratio of success around 0.2, and of failure  greater than 0.99.}
%\label{fig}
%\end{figure}

%We also analyze the ratio of success after a predicton of success and of failure after a prediction of failure:

%- Interaction bump has high ratios ($>0.99$) for both success and failure: the certitude of the interaction result is thus highly related to the presence of the affordance.

%- Interaction eat has a success ratio of 0.207 and a failure ratio $>0.99$. Thus, the signature successfully associated the interaction with its affordance, and the probability of success when the affordance is expected to be present is close to the probability of eating a fish as defined by environment properties.

%- Interaction move forward has a high success ratio ($>0.99$) and a failure ratio of 0.27. The interaction's failure is thus associated to the presence of its affordance instead of its presence. The failure ratio implies both contexts related to fishes and to walls.

%- Visual interactions related to seeing a red or a green object have high ratios of success ($>0.7$) and failure ($>0.99$). An interesting observation is that visual interactions related to seeing more distant objects have lower ratio of success. Indeed, distant objects have more chance of being hidden by another object while the agent perform the interaction.

%- Visual interactions related to seeing a blue object have a high ratio of failure ($>0.99$). The ratio of success is between 0.14 and 0.25.

%- Visual interaction that cannot be predicted due to the impossibility to detect its affordance (e.g. seeing a red element in a left position while turning let), have a very low ratio of success ($<0.05$) and a failure ratio lower than other interactions (between 0.95 and 0.99). The fact that the sum of success and failure ratio is close to 1 shows that the signatures fail to predict the result of these interactions. This property can be used by the learning selection mechanism to remove these interactions from candidate interactions.


%The principle presented in this section makes possible the emergence of signatures of interactions related to probabilistic affordances, and to estimate the probability of enaction. However the signatures merge all contexts affording an interaction, and does not differenciate the probability of each of these contexts, as observed for the move forward interaction. This limitation prevents the propagation of the signature and the estimated probability of a distant affordance, which is required for affordance detection. Next Section III-B address this limitation.


\subsection{Separating Possible Contexts}
%-n√©cessit√© de s√©parer les contextes qui peuvent avoir des probabilit√©s diff√©rentes
%-principe et impl√©mentation des signatures multi-neurones MAX

The detection of distant affordances (described in Section IV) requires to differentiate the possible contexts affording an interaction, and attribute a probability to each context.

We propose an adaptation of the signature mechanism, based on multiple neurons. Each signature $S_i$ consists of a set of $n$ neurons $N_k^i$ ; the neuron with the strongest output defines the prediction of the signature. In case of success, the neuron with the strongest output is reinforced, while a failure reinforce all neurons. This competition leads to a specialization of each neuron for a specific context, while they are desensitized from other contexts. Thus, with a sufficient number of neurons, a signature can identify contexts affording its interaction independently.

Formally, a neuron $k$ is defined as a set of weights $w_l^k$ (with $Card(\{w_l^k\})=Card(I)$, with an output defined as:
\begin{equation}
N_i^k(E_t)~=~f(\sum_{i} E_t[i] \times w[i])~,~ f(x) = { {1}\over{1+e^{-x} }}
\end{equation}
where the interactional context $E_t$ takes the form of a vector of size $Card(I)$, with $E_t[k]=1$ when interaction $i_k$ is enacted as a success and $E_t[k]=0$ otherwise.

Then, the response of the group is defined as the maximum output, and remapped to a range in $[-1;1]$:
\begin{equation}
N_i(E_t)~=~max_k (N_i^k(E_t) ) \: \times \: 2 ~+~ 1
\end{equation}
In order to consider interactions that are afforded by the absence of their affordance instead of their presence, we added an output weight $W_i$ defining the output of the signature:
\begin{equation}
S_i(E_t)~=~N_i(E_t) \times W_i
\end{equation}
The weight $W_i$ is restrained in the interval $[-1,1]$, allowing to inverse the result of the prediction, which makes neurons able to integrate contexts preventing the enaction of $i$.

The learning process uses a classical gradient descent:

%- The candidate signature $i$ stores the signature certitude $S^i$ output value $N^i$ and output value of each neuron $N_k^i$ of the signature. Once intended, the enaction of $i$ can be a success ($R_t=1$) or a failure ($R_t=-1$).

- The enaction result is defined as $R_t=1$ in case of success and $R_t=-1$ in case of failure.

- The weight $W_i$ is updated as follow:

$W_i ~\Leftarrow~ W_i+ \Delta^i . (\alpha * N_i - \alpha /2)$, ~with $\Delta^i=R_t-S_i(E_t)$
and $\alpha$ the learning rate.

- In case of a success, only the neuron with higher output is reinforced, all neurons are reinforced in case of failure:

$W_k^i ~\Leftarrow~ W_k^i+ \alpha . \Delta_k^i . N_k^i$,
with $\Delta_k^i=(R_t.W_i + 1)/2 - N_k^i$


%Note that the principle described in Section III-A is applied. 
To increase the specialization of neurons, in case of a success, weights of the most active neuron connected to failed interaction can be reduced (desensitizing this neuron from other contexts than the current one) and reducing weights of other neurons that are related to successful interactions (desensitizing other neurons from the current context).

%The signature $S_i$ can be subdivided into contexts $S_i^{j,n}$ identified by a neuron index $n$ and a primary interaction $j$ (i.e. the sub-set of weights of neuron $n$ of $S_i$ that are related to interaction $j$ and its associated secondary interactions). It is then possible to define the ratio of success and of failure of each context individually by updating ratios of the context $S_i^{j,n}$, designated by the enacted primary interaction $j$ and the most active neuron $n$.

A consequence of this implementation is that high weights of neurons characterize contexts affording an interaction. It is also possible to consider weighs of a neuron by primary interaction, each group containing a weight related to a primary interaction and weights related to its associated secondary interaction. Thus, a signature $S_i$ can be subdivided into minimal contexts $C_{j,n}^{S_i}$, associated to a primary interaction $j$ and a neuron $n$. It is then possible to define the ratio of success $p_{j,n}^{s,i}$ and of failure $p_{j,n}^{f,i}$ of each context individually by updating them when primary interaction $j$ is enacted and neuron $n$ has the highest activity, and $S_i(E_t)<\overline{S_i^s}$ or $S_i(E_t)>\overline{S_i^f}$.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.7]{img/signature_model2.pdf}}
\caption{Signature architecture based on multiple neurons. As the signature output relies on the neuron with greatest output, neurons are in competitions with each other, leading to a specialisation of each neuron for a specific context. The last function remaps the output to range $[-1;1]$ and uses a global weight $W_i$, that can inverse the signature result, allowing the representation of contexts preventing the enaction of an interaction.}
\label{fig}
\end{figure}

\subsection{Implementation}

This signature mechanism was tested on an artificial agent moving in a 2-dimensional discrete environment. The sensorimotor possibilities of the agent define a list of five primary interactions, listed below:

- \includegraphics[width=0.015\textwidth]{img/mf0.pdf} move forward by one step

- \includegraphics[width=0.015\textwidth]{img/mf1.pdf} bump in a solid element 

- \includegraphics[width=0.015\textwidth]{img/mf2.pdf} eat something edible 

- \includegraphics[width=0.02\textwidth]{img/rt0.pdf} turn right by $90^\circ$ 

- \includegraphics[width=0.02\textwidth]{img/lt0.pdf} turn left by $90^\circ$ 

Interactions move forward, bump and eat are considered as mutually alternative: intending one of these interactions may lead to the enaction of one of the two others instead. %(and thus the failure of this interaction).

We add a set of secondary interactions provided by the agent‚Äôs visual system, that can detect colors among {red,green, blue}, and measure distances.  Secondary (visual) interactions consist in seeing a red, green or blue element while enacting a primary interaction, at a certain (but initially unknown) position of space. The interaction bump, that does not produce movement, does not generate visual interactions. We discretize the visual field as a regular grid of 15 √ó 8 positions centered on the agents that matches the grid of the environment. We thus define 4 √ó 3 √ó 15 √ó 8 = 1440 possible secondary interactions.
Signatures are implemented as set of 6 neurons. % (Section V discusses on the possibilities of dynamic arrays of neurons).

As we only study the emergence of signatures, we define a unique learning mechanism that foster interactions with low certitude of success or failure. Note that a secondary interaction can be candidate if its associated primary interaction is predicted as a success with a high certitude.

The environment is populated by three types of objects offering spatial regularities that the agent can discover by interacting with them, and characterized by a color that makes them recognizable through agent's sensorimotor system:

- wall (green), affording bump

- algae (red), that are walkthroughable (and thus useless in the agent's perspective).

- fishes (blue), affording eat.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.35]{img/environment.pdf}}
\caption{Test environment. The agent is represented as a grey shark (bottom left), wall as green blocks, algae as red leafs and mobile preys as blue fishes.at each simulation step, the fish has 20\% of remaining at current position or to move up, down, left and right. When an obstacle prevents from moving in the selected direction, the fish does not move. This behavior simulate an agent with unknown decisional mechanism.}
\label{fig}
\end{figure}

The fishes move randomly in the environment: at each simulation step, a fish can move in one of these five directions, with a probability of 20\%: immobile, left, right, top, bottom. If the fish cannot move in the selected direction because of an obstacle (wall, alga or other fish), the fish remains at its current position, making the immobile situation probability slightly higher than other directions. This random movement simulates agents with unknown behavior. All object are opaques: the agent cannot perceive an element behind another one.


%\begin{figure}[htbp]
%\centerline{\includegraphics[scale=0.5]{img/Signatures1.pdf}}
%\caption{Signatures of bump (left column), and seeing green while moving forward (middle) and seeing red while turning left (right) at positions identified by a red square. These signatures were recorded after 100 000 simulation steps. A signature is characterized by a set of weights of 7 formal neurons. As external observers, we can organize these weights to make signatures more readable. First, weights of secondary interaction are grouped according to their associated primary interaction (from top to bottom: forward, eat, turn left, turn right). Weights associated to primary interactions and the bias are represented with squares below. Then each group is organized to match the associated position in space, relative to the agent (orange triangle). Finally, colors are overlapped to generate signatures under the form of a RGB image. As these signatures identified a unique context affording these interaction, unused neurons' weights are not represented. Interaction bump (left) is afforded by a green object in front of the agent, but also after bumping. The offset between the position associated to visual interactions and the position of their affordance correspond to the movement produced by their associated primary interaction. This property is exploited to project signatures and detect distant affordances.}
%\label{fig}
%\end{figure}


\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.5]{img/Signatures1_3.pdf}}
\caption{Signatures of interaction \textit{bump}, recorded after 100 000 simulation steps. A signature is characterized by the weights of 6 formal neurons, each neuron being represented by a column. As the signature identified a unique context, we only represent weights of one neuron. As external observers, we can organize weights of a neuron to make signatures more readable: first, weights associated with primary interactions are represented with five squares below (green for a positive weight, red for a negative weight). Weights associated with secondary interaction are grouped according to their primary interaction, forming the four groups (from top to bottom: forward, eat, turn left, turn right ; bump does not produce visual interactions). Each group is organized to place visual interaction with their associated position in space, relative to the agent (orange triangle). Colors associated with visual interactions are overlapped to generate signatures under the form of a RGB image. Signature of bump identified a context that consist of seeing a green element in front of the agent, which correspond, from an external observer perspective, to the presence of a wall in front of the agent. Bump is also related to the success of bump: indeed, the agent can bump repeatedly. The signature thus gathered every interaction allowing to detect the presence of a wall in front of the agent.}
\label{fig}
\end{figure}


%\begin{figure}[htbp]
%\centerline{\includegraphics[scale=0.5]{img/Signatures1_4.pdf}}
%\caption{Signatures two visual interactions, identified by red squares: seeing green element while moving forward and seeing red element while turning left. As only one context was identified by these signatures, we only display weights of a unique neuron. The offset between the position associated with the visual interactions and the position of their affordance correspond to the movement produced by their associated primary interaction. Signatures thus encode spatial properties of primary interactions, that are exploited to detect distant affordances.}
%\label{fig}
%\end{figure}





We then let the agent behaves in its environment, driven by the signature learning mechanism. Signature of bump emerges and stabilizes in nearly 5000 simulation step. The signature is similar to signature obtained in static environments [ ], and associates the success of bump to the presence of 'seeing a green element in the position in front of the agent', and of a previously enacted 'bump'. The signature gathered these interactions, even through they are associated to different primary interactions. %, showing how a signature can gather multiple sensory modalities.

Signatures of secondary interactions related to static elements (seeing red and seeing green) progressively stabilize, depending of they frequency of occurrence. After 50 000 simulation steps, most of these signatures stabilized. These signatures are also similar to signatures obtained in static environments [ ]. They designate elements of the same color but on a different position in space. From an external point of view, the spatial offset between the visual secondary interaction and the element designated by its signature matches the movement performed by the enation of its associated primary interaction. This property is used for signature projection and distant affordance detection [ ] (details in Section IV).

Signatures of interactions related to mobile elements require more steps, as they relate to a larger variety of contexts to identify: at least 45 000 steps are required to identify contexts affording eat and move forward. Signature of interaction eat characterizes five contexts corresponding to the five positions of fish that can lead to a success of eat. Note that the position under the agent does not appear in contexts of interactions associated to move forward, as this situation is not possible. The signature of move forward has a negative weight $W$. The signature thus shows the affordance that prevents this interaction. The signature designates five contexts associated to the presence of a fish, and one context associated to the presence of a wall in front of the agent.

%The signatures emerge within a similar number of interaction test than previously. Signature of interaction bump stabilizes in nearly 5000 simulation steps, and associates only one context characterizing the presence of a green object in front of the agent. Signature of interaction eat characterizes five contexts corresponding to the five positions of fish that can lead to a success of eat. Note that the position under the agent does not appear in contexts of interactions associated to move forward, as this situation is not possible. The signature of move forward has a negative weight $W$. The signature thus shows the affordance that prevents this interaction. The signature designates five contexts associated to the presence of a fish, and one context associated to the presence of a wall in front of the agent.

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.35]{img/sig_forward.pdf}}
\caption{Signature of \textit{move forward}, recorded after 100 000 simulation steps. Each column represents a neuron of the signature. The weight W is negative: the signature thus represents contexts \textit{preventing} moving forward. The signature identifies six contexts, represented (from an external point of view) above. As a fish cannot be below the agent after forward or eat, only 5 contexts are related to forward primary interaction (greyed context has low weights and is thus unused by the signature). As eat interaction is rarely enacted, contexts related to this primary interaction (second line) are still constructing, although context related to the wall context is already formed on fourth neuron.}
\label{fig}
\end{figure}

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.35]{img/sig_eat.pdf}}
\caption{Signature of eat. The weight W is positive: the signature thus represents contexts affording eat. The signature identifies 5 configurations of fish (front, ahead, left, right, below), 4 in the case of a move forward (as below context cannot be observed). In contexts with fish around front position, we can observe the absence of a green or red element (dark blob) in front of the agent, as this would prevent the prey from moving to this position.}
\label{fig}
\end{figure}

\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.35]{img/sig_blue.pdf}}
\caption{Signature of secondary interaction seeing a blue element at the position identified with a red square, while moving forward. The weight W is positive. The signature identifies 5 configurations of fish. The signature also indicates the absence of an element that would prevent the fish from moving on the right place, but also elements that could hide the fish (dark blobs).}
\label{fig:sigblue}
\end{figure}

Signatures of secondary interactions consisting in seeing blue elements designate five contexts, corresponding to the five positions leading to a success of these interactions.

%The probabilities of signature contexts related to fully predictible and non-predictible interactions are similar than previously. However, signatures designating probabilistic affordances have different probabilities for each context.

We also analyze the ratio of successful enaction after a prediction of success. The ratios obtained in contexts implying static objects (such as walls) are close to 1: this indicates that the presence of this type of affordance implies the success of the interaction. Ratios obtained in contexts implying mobile fishes are close to 20\%, which correspond to the probability that the fish move in the right direction allowing the agent to eat it. The contexts with a fish in front of the agent is however slightly greater. This can be explained by the fact a prey cannot move a a different position when blocked by a wall or an alga, increasing the probability of eating the fish when in front of the agent.


\begin{table}[htbp]
\caption{Average ratios of success when predict a success and failure when predict a failure in each type of context (wall, fish in front, fish in other positions (surrounding)}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline 
\textbf{interaction} & \textbf{\textit{ratio of success}}& \textbf{\textit{ratio of failure}} \\
\hline
forward (wall)& 0.96 &  0.999 \\
\hline
forward (front)& 0.25& 0.999 \\
\hline
forward ('surrounding')& 0.19 & 0.999 \\
\hline
bump (wall)& 0.97 & 0.999 \\
\hline
eat (front)& 0.24 & 0.999 \\
\hline
eat ('surrounding')& 0.19 & 0.999 \\
\hline
seeing blue (Fig. \ref{fig:sigblue}) (middle)& 0.24 & 0.999 \\
\hline
seeing blue (Fig. \ref{fig:sigblue}) ('surround.')& 0.18 & 0.999 \\
\hline
\end{tabular}
\label{tab1}
\end{center}
\end{table}

These signatures can thus be projected to detect distant affordances. The probability of each context is also used to define the probability of future enaction of interactions.



\section{Localizing Distant Affordances}

The detection of distant affordances relies on a property of signatures as defined in a RI model: a signature of an interaction designates an affordance under the form of sets of interactions ~$\{j_k\} \in \hat{S}_i(1)$ allowing to define the presence of this affordance.
However, each interaction $j_k$ can have its own signature, and each context $C_l=\{j_k\}$ affording $i$ is composed of interactions $j_k$ related to the same primary interaction $j$. The backmove principle thus propose to \textit{project} a signature $S_i$ through a primary interaction $j$ using the following procedure: we note $\hat{S}_i^{\sigma_0} = \hat{S}_i(1)$, where $\sigma_0$ is an empty sequence of interactions, and construct:
$\hat{S}_i^{[j,\sigma_0]}\!=\!\bigcup_{\forall C_l \in \hat{S}_i^{\sigma_0} / j \in C_l} \{E \in \mathcal{P}(I) / \forall j_k \in C_l, S_{j_k}(E)\!>\!0\}$, which characterizes contexts that can afford $i$ after enacting $j$.

As this process can be repeated by considering $\sigma_{a+1}=[j,\sigma_a]$, it is possible to \textit{backmove} a signature $S_i$ by a sequence of interactions $\sigma$, to obtain a \textit{predecessor} of $i$, noted $S_i^\sigma$. A predecessor $S_i^\sigma$. characterizes a set of contexts $\hat{S}_i^\sigma$ that, if \textit{moved} through the enaction of the sequence of interactions $\sigma$, affords~$i$. Then, when a predecessor $\hat{S}_i^\sigma$ is observed in the context $E_t$, a distant affordance of $i$ is assumed to be present at a position characterized by sequence $\sigma$, in egocentric reference.

%- principe du proto-objet\newline

%In [ ], authors proposed the notion of proto-object as a partial projection of the signature of an interaction, allowing to detect incomplete affordances that can be assembled, but that can also be used to detect candidate positions of affordances without projecting the whole signature. Formally, a proto-object is a sub-part of a predecessor: $\hat{S}_i^{\sigma *}\!\subset\!\hat{S}_i^\sigma, \hat{S}_i^{\sigma *}\!\neq\!\emptyset$

\subsection{Backmoving a probabilistic affordance}

Applying the backmove principle to a signature of a probabilistic affordances would generate a set of predecessor covering all possible future positions of this affordance after enacting a sequence $\sigma$, leading to a detection of an affordance through multiple positions in space.
% the set of predecessor defining the position of the affordance as a 'probability wave' that extends while the sequence $\sigma$ is growing.
%A unique mobile element of the environment would thus be detected a set of different positions. %, whose 'probability waves' cover this element.
%However, this localization through multiple position cannot be exploited by the space memory architecture, as requires to consider affordances with unique positions in space.
%We thus propose to only consider predecessors that have the greatest probability, defining a unique position of an affordance in surrounding space. %, for a given sequence $\sigma$, as the maximum of the 'probability wave'.
Such a multiple localization cannot be exploited by a Space Memory. We thus propose to define the position of an affordance as the most probable predecessor that can be observed through a sequence~$\sigma$.

The proposed backmove method introduces a new structure, called projection sequence. The idea is to split predecessors into individual interactions: for each backmove, each sequence considers a unique interaction of $S_i^{\sigma}$.
%The predecessors can then be reconstructed by gathering projection sequences that have the same properties. %The projection sequences thus relate to the notion of proto-objects [ ] that consists in backmoving only a part of the signature to detect incomplete affordances and facilitates detection of distant affordances.

A projection sequence $\xi$ is a structure characterized by:

- a sequence $\sigma$ of primary interactions, characterizing the movement required to reach the affordance,

- a sequence $\lambda$ of primary or secondary interactions, that characterize the successive projections from an interaction to an interaction of its signature (principle of backmove).

- a sequence $\eta$, indicating the contexts that interactions of $\lambda$ belong to.

- a probability $p$ characterizing the probability of enacting $i$ from the partial affordance characterized by the projection sequence.


The set of projection sequence is constructed as follow: from a signature $S_i$, a first set of sequence $([\:], [j_k], [n], p_0)$ is generated for each interaction $j_k$ designated by $S_i$, where $\sigma=[\: ]$ the initial (empty) backmove sequence, $\lambda=[j_k]$, $n$ is the index of the context containing $j_k$ and $p$ is the success ratio of the context containing $j_k$. Note that this set characterizes $S_i$ under the form of projection sequences.

Then, the set of sequences is recursively backmoved. A sequence $(\sigma, \lambda, \eta, p)$ leads to interaction $\lambda[0]$. This sequence is backmoved by primitive interaction $j$ associated to $\lambda[0]$ (or by $\lambda[0]$ if primary): from signature $S_{\lambda[0]}$, a set of sequences $([j,\sigma], [j_k,\lambda], [n,\eta], p*p_{S_{\lambda[0]}^{j,n}})$ is generated, for each interaction $j_k$ designated by $S_{\lambda[0]}$.

%Sequence filter is applied during the sequence construction process.
A sequence $\xi_1$ is removed from the list if it exists another sequence $\xi_2$ with $p_{\xi_2}>p_{\xi_1}$ that have similar properties:

- same backmove sequence ($\sigma_1=\sigma_2$)

- same final interaction ($\lambda_1[0]=\lambda_2[0]$)

- divergence comes from different contexts ($\exists k, \lambda_{\xi_2}[k+1]=\lambda_{\xi_2}[k+1] \wedge \lambda_{\xi_2}[k] \neq \lambda_{\xi_2}[k] \wedge \eta_{\xi_2}[k] \neq\eta_{\xi_2}[k]$). This property implies that the two sequences are related to two possible, exclusive, future position of the affordance instead of the same context.

The set of projection sequences of a signature $S_i$ provides, for each interaction $i \in I$, a set of most probable sequence of interactions linking interactions from a context $E_t$ and elements designated by $S_i$.
%These sequences can then be used to detect and confirm the presence of an affordance at position characterized by $\sigma$.





%- fusion des proto-objets pour obtenir les proto-objets les plus probables\newline

%Principe du backmove (√Ä FORMALISER):

%- Une signature est constitu√©e d'un ensemble de contextes $\{j_k\}_{i,n}$ contenant des interactions associ√©es √† une interaction primaire $j$ et un neurone $n$.

%- Pour chaque contexte $(i,n)$, et pour chaque interaction $j_k$ de $\{j_k\}_{i,n}$, on cr√©√© une sequence de projection $S = (\sigma,inter, neuro,p)$ avec $\sigma=[]$ une s√©quence vide, $inter=[j_k]$, $neuro=[n]$ et $p$ la probabilit√© associ√©e au contexte $(i,n)$. 

%$\sigma$ est la s√©quence de 'mouvement'

%inter est la s√©quence des interactions projet√©es

%neuro est la s√©quence des contextes utilis√©s

%p est la probabilit√© globale de la s√©quence

%- Pour 'projeter' une s√©quence $S$ avec une interaction primaire $i$ :

%On utilise la signature de la derni√®re interaction de la s√©quence $inter$. Pour chaque contexte $\{j_k\}_{i,n}$ de la derni√®re interaction, on g√©n√®re une nouvelle s√©quence d√©finie par :

%$S = ([\sigma,i],[inter, j_k], [neuro,n],p*p_1)$

%Ainsi, la s√©quence $S$ consid√®re $j_k$ comme √©tant une partie de la projection de la signature d'origine, projet√©e par une s√©quence 'mouvement' $\sigma$.

%Probl√®me : me fait qu'il y ait plusieurs contextes par signature augmente l'explosion combinatoire, et complexifie le calcul de la probabilit√© de l'affordance.

%L'id√©e consiste √† d√©terminer uniquement la position la plus probable de l'affordance, qui sera consid√©r√©e comme unique.

%Fusion des s√©quences : on attribue une seconde valeur de probabilit√©, appel√©e probabilit√© globale.
%Si deux s√©quences sont caract√©ris√©es par une m√™me s√©quence $\sigma$, une m√™me interaction d'arriv√©e (dernier √©l√©ment de la s√©quence inter), et que leur s√©paration n'est pas issue d'un m√™me contexte ($inter[i]=inter'[i] et inter[i+1]!=inter'[i+1]$, on ne doit pas avoir $neuro[i+1]=neuro'[i+1]$), alors on ne garde que la s√©quence avec la probabilit√© la plus √©lev√©e. En supprimant l'autre s√©quence, sa probabilit√© globale s'ajoute √† celle de la s√©quence restante.

%On s'assure ainsi que pour chaque interaction et chaque s√©quence $\sigma$, il n'y ait qu'une seule s√©quence $neuro$ de contexte.

%Formally, a projection sequence is defined as a couple of sequences of primary interaction, characterizing the movement in space, and of interaction (primary or secondary) used during the propagation.

%- g√©n√©ralisation du principe ci-dessus pour d√©tecter la pr√©sence des affordances (position la plus probable)\newline



\subsection{Detection of distant affordances}

The position of an affordance in space is defined as sequences $\sigma$ whose enaction would allow to enact the afforded interaction. The sequence is considered regardless of its enactability: the position of an affordance is considered independently from its accessibility.

%Ls positions des affordances sont d√©finies par des s√©quences d'interaction primaires qui, si elles √©taient √©nact√©es, permettraient d'√©nacter l'inteaction consid√©r√©e. Notons que l'on ne tient pas compte de l'√©nactabilit√© des interactions de la s√©quence : on localise un objet ind√©pendamment de son accessibilit√©.

Projection sequences can be used to detect potential affordances: if a sequence of a signature $S_i$ has its last interaction enacted (i.e. $\lambda[0] \in E_t$), then a part of the context affording $i$ is present at position $\sigma$. However, a sequence only characterizes a part of the affordance ; a larger part of the context must be evaluated to confirm the presence of the whole affordance.
%It is thus required to evaluate a larger part of the current context to confirm the presence of the affordance.

%It is not possible to simply simulate the evolution of the context by recursively evaluating the certitude of secondary interactions associated to interactions of $\sigma$: as several objects can move, multiple possibilities of future contexts can emerge, with multiple combination in case of multiple mobile elements.

%The projection sequences solve this problem, as they only consider the most probable evolution of positions.
The detection of distant affordances of an interaction $i$ starts by selecting projection sequences $\xi_k^i$ of signature $S_i$ whose last element is enacted, defining \textit{candidate} affordances of $i$. Each candidate $\xi_k^i$ gathers a set of sequences $\Theta_{\xi_k^i} = \{\xi_l^i ~/~ \sigma_l = \sigma_k \wedge \lambda_l[0] \in E_t\}$, sharing the same sequence $\sigma$ and whose last element $\lambda[0]$ is enacted. %of sequences with the same $\sigma$ and whose  ($\lambda[0]\in E_t$).

The set $E_k^0=\{\lambda_l[0] ~/~\xi_l \in \Theta_{\xi_k^i}\}$ of last interaction of sequences of an ensemble $\Theta_{\xi_k^i}$ represents an ensemble $E_k^0 \subset E_t$ gathering interactions that can intervene in the presence of the affordance.
From the context $E_k^0$ of a candidate $\xi_k^i$, the following recursive procedure is applied: elements $\lambda[1]$ of sequences are gathered into a candidate context $C^1$ (duplicate interactions are removed). Then, each element of $C^1$ is evaluated with its signature on context $E^0$. Interactions predicted as a failure are removed from $C^1$, and their projection sequences, removed from $\Theta_{\xi_k^i}$. Remaining interactions of $C^1$ define context $E^1$. The process is repeated with $C^{l+1}$, until sequence $\sigma$ is completed (or until $\Theta_{\xi_k^i}$ is empty). Interaction $i$ is then predicted using $S_i(E^l)$. If the signature predicts a success, the affordance of $i$ is confirmed at position~$\sigma$.

Confirmed affordances of the same interaction can then be gathered if they are characterized by the same elements of the context. the different sequences $\sigma$ thus indicate the different way to reach this affordance.
%Note that the space memory only considers shortest sequences to characterize the position of an affordance.

%Potentiellement, toutes les s√©quences de projection dont le dernier √©l√©ment a √©t√© √©nact√© peut indiquer la pr√©sence d'une affordance. La pr√©sence de l'affordance doit ensuite √™tre v√©rifi√©e en testant le contexte dans son ensemble. Afin de limiter les s√©quences candidates, on s'inspire des proto-objects.

%L'id√©e consiste √† g√©n√©rer des s√©quences de projections, en n'utilisant qu'une seule interaction par contexte. Dans le cas d'une impl√©mentation √† base de neurones formels, on peut utiliser le poids positif le plus √©lev√©. Ceci permet d'obtenir une liste de s√©quences de projections dont l'interaction cible est particuli√®rement pertinente (mais pas forc√©ment suffisante) pour indiquer la pr√©sence de l'affordance.

%Une fois la liste des s√©quences $\sigma$ candidates obtenue, la d√©tection suit la proc√©dure suivante :

%- On r√©cup√®re la liste des s√©quences de projection avec la m√™me s√©quence $\sigma$ et dont le dernier √©l√©ment est enact√©. √Ä noter : la liste des derni√®res interactions des s√©quenes S est une sous-partie du contexte $E_t$ pouvant faire partie de l'affordance. Ce sous-contexte constitue le contexte de test $E_0^{test}$. 

%- Pour chaque √©tape $t$ de $\sigma$, on r√©cup√®re la liste des interactions inter[t+1], que l'on pr√©dit dans le contexte $E_{t}^{test}$. Les s√©quences des interactions pr√©dites comme √©chec sont √©limin√©es, les interactions pr√©dites comme un succ√®s forment le nouveau contexte de test $E_{t+1}^{test}$.

%Une fois la s√©quence $\sigma$ simul√©e, on teste l'interaction $i$ dans le dernier contexte de test. Si l'interaction est pr√©dite comme un succ√®s, la pr√©sence de l'affordance est confirm√©e √† la position $\sigma$. 

\subsection{Test Environments}

The affordance detection mechanism was tested with signatures recorded after 150 000 simulation steps in the environment described in Section III-2. The projection mechanism is added to the architecture, and used to generate projection sequences, with a maximum length up to 7 interactions.

As we implemented signature with neurons, we had to adapt the projection sequence construction mechanism. First, we only project interactions designated by a signature with a weight with an absolute value that is greater than a threshold, eliminating non-significant weights. Then, we had to cope with low weights that generate sequences with higher probability than weights with higher (and thus more representative of the affordance). We added a new property to projection sequences, the global weight, characterizing the pertinence of the sequence to represent the affordance. This global weight is computed as follow: first sequences have a global weight defined as $w^{global} = W_S \times w_k$. Then each backmove through a weight $w_k$ of a signature $S$, the global weight of the new sequence is updated as $w^{global}=w^{global} \times  W_S \times w_k$. The filter mechanism then compare values $p \times w^{global}$ instead of $p$ alone, offering a good compromise between probability and pertinence of sequences.



%- description des environnements de test\newline

%We used signatures obtained in the environment described in Section III-2. Signatures are recorded after 150 000 simulation steps. The projection mechanism is then added to the architecture, and used to generate projection sequences, with a maximum length up to 7 interactions. 

The agent is then presented different environment configurations, and an enaction cycle is performed to let the agent perceive its environment through enacted interactions. The sequences of detected affordances are then analyzed.

%Utilisation d'une valeur de poids globale qui est multipli√©e par le poids utilis√© par la projection, √† chaque nouvelle projection.

%La comparaison entre deux s√©quences de projection utilise le produit probabilit√© x poids\_global.

%- analyse des r√©sultats\newline


\begin{figure}[htbp]
\centerline{\includegraphics[scale=0.45]{img/detection.pdf}}
\caption{Detection of distant affordances. The agent is presented several elements affording its interactions. These distant affordances are detected and localized through sequences of interactions allowing to reach them. Circles show the position and orientation associated to these sequences (red: not moving forward, blue: eat, green: bump). We can notice that the agent ignore the alga, as it as the same interactional property than an empty space.}
\label{fig}
\end{figure}

Figure N shows the detection in a context containing two wall blocks, two fishes and an alga. Sequences localizing static objects (walls) allows to move toward them. Sequences localizing fishes does not reach the position of the prey, but a position just next to it. Indeed, as the agent can eat a fish on its side with only a sligtly lower probability than in front of it, the resulting sequence is a compromise between probability and length of the sequence. Alga is ignored, as it has the same property than empty space. Thus, the affordance detection mechanism can still detect and localize distant affordances under the form of sequences of interactions, which can be stored and exploited by the space memory in a similar way than in a static environment.


\section{Conclusion and Future Work}

This work propose a new mechanism to enable an environmentally agnostic agent to consider mobile and non-predictable elements in its emergent model of the environment. Results obtained in a simulated environment showed that the agent can still detect position of distant affordances without the notion of space, and define these position in a similar way than in static environment, allowing the use of a space memory.

Future work will study how the space memory can be used in such a stochastic environment, and how intrinsically motivated decisionnal mechanism can integrate probabilities of presence of affordance into consideration.

We will also implement these mechanisms in multi-agent contexts, to study the mutual integration of agents in their own environmental model, and how these models can be exploited for generating behaviors solving collaborative tasks, such as coordinate hunting of large preys. We also plan to study the possibility of predicting other agent's intentions through observation of its own context, as a previous implementation of the space memory demonstrated the possibility for reference change, opening intersubjectivity possibilities between agents.

%- r√©sum√© de la contribution\newline
%- adaptation de la m√©moire spatiale et des m√©canismes d'exploitation\newline
%- √©tude de comportements collaboratifs\newline
%- possibilit√© de pr√©dire les interactions d'autres agents √† partir de leur contextes propres (changement de r√©f√©rentiel)\newline


\bibliographystyle{IEEEbib}
\bibliography{refs, refs_og}

\end{document}
